<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kubernetes部署利器-kubeadm]]></title>
    <url>%2F%E6%8A%80%E6%9C%AF%E6%8A%80%E8%83%BD%2F%E5%85%A8%E9%9D%A2%E6%8B%A5%E6%8A%B1kubernetes%2FKubernetes%E9%83%A8%E7%BD%B2%E5%88%A9%E5%99%A8-kubeadm%2F</url>
    <content type="text"><![CDATA[kubeadm介绍kubeadm是芬兰一个17岁的高中生写的一个社区项目。目前还不能用于生成环境。 kubeadm能够帮我们省去很多麻烦，而且比较接近原生部署的感觉，这对我们入门学习k8s部署来说，不失为一个利器。 用户只需要执行两条命令就可以完成k8s集群的部署： 12345# 创建一个 Master 节点$ kubeadm init# 将一个 Node 节点加入到当前集群中$ kubeadm join &lt;Master 节点的 IP 和端口 &gt; 那kubeadm究竟做了什么事情呢？ kubeadm init 的工作流程 kubeadm 首先要做的，是一系列的检查工作，以确定这台机器可以用来部署 Kubernetes。例如内核版本，网络是否可用，必要的命令是否齐全等。 在通过了 Preflight Checks 之后，kubeadm 要为你做的，是生成 Kubernetes 对外提供服务所需的各种证书和对应的目录。kubeadm 为 Kubernetes 项目生成的证书文件都放在 Master 节点的 /etc/kubernetes/pki 目录下。 证书生成后，kubeadm 接下来会为其他组件生成访问 kube-apiserver 所需的配置文件。这些文件的路径是：/etc/kubernetes/xxx.conf。 接下来，kubeadm 会为 Master 组件生成 Pod 配置文件。 Master 组件 kube-apiserver、kube-controller-manager、kube-scheduler，而它们都会被使用 Pod 的方式部署起来。这些Pod并不会在此阶段被执行，而是等kubelet启动的时候，加载这些文件并执行的。由此可以看出，kubelet在k8s的地位非常高，其他master组件更像是辅助性的系统容器。 在 Kubernetes 中，有一种特殊的容器启动方法叫做“Static Pod”。它允许你把要部署的 Pod 的 YAML 文件放在一个指定的目录里。这样，当这台机器上的 kubelet 启动时，它会自动检查这个目录，加载所有的 Pod YAML 文件，然后在这台机器上启动它们。在 kubeadm 中，Master 组件的 YAML 文件会被生成在 /etc/kubernetes/manifests 路径下。比如，kube-apiserver.yaml。 12 ls /etc/kubernetes/manifests/etcd.yaml kube-apiserver.yaml kube-controller-manager.yaml kube-scheduler.yaml 然后，kubeadm 就会为集群生成一个 bootstrap token。在后面，只要持有这个 token，任何一个安装了 kubelet 和 kubadm 的节点，都可以通过 kubeadm join 加入到这个集群当中。 在 token 生成之后，kubeadm 会将 ca.crt 等 Master 节点的重要信息，通过 ConfigMap 的方式保存在 Etcd 当中，供后续部署 Node 节点使用. kubeadm init 的最后一步，就是安装默认插件。Kubernetes 默认 kube-proxy 和 DNS 这两个插件是必须安装的。它们分别用来提供整个集群的服务发现和 DNS 功能。其实，这两个插件也只是两个容器镜像而已，所以 kubeadm 只要用 Kubernetes 客户端创建两个 Pod 就可以了。 kubeadm join 的工作流程kubeadm init 生成 bootstrap token 之后，你就可以在任意一台安装了 kubelet 和 kubeadm 的机器上执行 kubeadm join 了。 任何一台机器想要成为 Kubernetes 集群中的一个节点，就必须在集群的 kube-apiserver 上注册，而token就是认证的手段。 配置 kubeadm 的部署参数可以在初始化的时候传入配置文件： 1kubeadm init --config kubeadm.yaml 下面是kubeadm.yaml的一个示例： 123456789101112131415161718192021222324252627apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0api: advertiseAddress: 192.168.0.102 bindPort: 6443 ...etcd: local: dataDir: /var/lib/etcd image: &quot;&quot;imageRepository: k8s.gcr.iokubeProxy: config: bindAddress: 0.0.0.0 ...kubeletConfiguration: baseConfig: address: 0.0.0.0 ...networking: dnsDomain: cluster.local podSubnet: &quot;&quot; serviceSubnet: 10.96.0.0/12nodeRegistration: criSocket: /var/run/dockershim.sock ... 通过制定这样一个部署参数配置文件，你就可以很方便地在这个文件里填写各种自定义的部署参数了。比如，我现在要指定 kube-apiserver 的参数，那么我只要在这个文件里加上这样一段信息： 123456...apiServerExtraArgs: advertise-address: 192.168.0.103 anonymous-auth: false enable-admission-plugins: AlwaysPullImages,DefaultStorageClass audit-log-path: /home/johndoe/audit.log 然后，kubeadm 就会使用上面这些信息替换 /etc/kubernetes/manifests/kube-apiserver.yaml 里的 command 字段里的参数了。 这个配置文件的可配置项远不止这些，在后面再慢慢探索。]]></content>
      <categories>
        <category>技术技能</category>
        <category>全面拥抱kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[初识Kubernetes]]></title>
    <url>%2F%E6%8A%80%E6%9C%AF%E6%8A%80%E8%83%BD%2F%E5%85%A8%E9%9D%A2%E6%8B%A5%E6%8A%B1kubernetes%2F%E5%88%9D%E8%AF%86kubernate%E7%9A%84%E6%9E%B6%E6%9E%84%E4%BD%93%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[一个正在运行的 Linux 容器，其实可以被“一分为二”地看待： 一组联合挂载在 /var/lib/docker/aufs/mnt 上的 rootfs，这一部分我们称为“容器镜像”（Container Image），是容器的静态视图； 一个由 Namespace+Cgroups 构成的隔离环境，这一部分我们称为“容器运行时”（Container Runtime），是容器的动态视图。 从一个开发者和单一的容器镜像，到无数开发者和庞大的容器集群，容器技术实现了从“容器”到“容器云”的飞跃，标志着它真正得到了市场和生态的认可。 而能够定义容器组织和管理规范的“容器编排”技术，则当仁不让地坐上了容器技术领域的“头把交椅”。而Kubernetes则是坐上了头把交椅的老大。 Kubernetes的技术起源Kubernete技术理论基础得益于谷歌的Borg系统。Borg 系统，一直以来都被誉为 Google 公司内部最强大的“秘密武器”。虽然略显夸张，但这个说法倒不算是吹牛。 因为，Borg 要承担的责任，是承载 Google 公司整个基础设施的核心依赖。在 Google 公司已经公开发表的基础设施体系论文中，Borg 项目当仁不让地位居整个基础设施技术栈的最底层。 所以，Kubernetes 项目从一开始就比较幸运地站上了一个他人难以企及的高度。 Kubernetes的全局架构 控制节点(Master)即Master 节点，由三个紧密协作的独立组件组合而成。 kube-apiserver：负责 API 服务； kube-scheduler：负责调度； kube-controller-manager：负责容器编排。而整个集群的持久化数据，则由 kube-apiserver 处理后保存在 Etcd 中。 计算节点（note）计算节点上最核心的组件，就是kubelet。kubelet通过接口和规划跟其他组件打交道。 (1) kubelet 同容器运行时打交道。交互所依赖的，是一个称作 CRI（Container Runtime Interface）的远程调用接口，这个接口定义了容器运行时的各项核心操作，比如：启动一个容器需要的所有参数。也就是说，只要这个容器运行时能够运行标准的容器镜像，它就可以通过实现CRI接入到Kubernetes项目当中。 而Container Runtime容器运行时，则通过 OCI 这个容器运行时规范同底层的 Linux 操作系统进行交互，即：把 CRI 请求翻译成对 Linux 操作系统的调用（操作 Linux Namespace 和 Cgroups 等）。 (2) kubelet 通过 gRPC 协议和 Device Plugin 的插件进行交互。这个插件，是 Kubernetes 项目用来管理 GPU 等宿主机物理设备的主要组件，也是基于 Kubernetes 项目进行机器学习训练、高性能作业支持等工作必须关注的功能。 (3) 调用网络插件Networking和存储插件Device Plugin为容器配置网络和持久化存储。这两个插件与 kubelet 进行交互的接口，分别是 CNI（Container Networking Interface）和 CSI（Container Storage Interface）。 Kubernetes核心功能全景Kubernetes要解决的是什么问题？实际上，这个问题到目前为止都没有固定的答案。因为在不同的发展阶段，Kubernetes 需要着重解决的问题是不同的。 可以从两个方面来回答： 处理集群中的各种任务之间存在着各种各样的关系。 处理应用运行形态的问题。 我们可以通过下面这幅图，按照这幅图的线索，来探索下Kubernetes的功能演进路线。 处理应用之间的关系 首先遇到了容器间“紧密协作”关系的难题，于是就扩展到了 Pod；Pod之间可共享网络和存储等资源。 有了 Pod 之后，我们希望能一次启动多个应用的实例，这样就需要 Deployment 这个 Pod 的多实例管理器； 而有了这样一组相同的 Pod 后，我们又需要通过一个固定的 IP 地址和端口以负载均衡的方式访问它，于是就有了 Service。 不同 Pod 之间不仅有“访问关系”，还要求在发起时加上授权信息。于是有了Secret。它其实是一个保存在 Etcd 里的键值对数据。这样，你把 Credential 信息以 Secret 的方式存在 Etcd 里，Kubernetes 就会在你指定的 Pod（比如，Web 应用的 Pod）启动时，自动把 Secret 里的数据以 Volume 的方式挂载到容器里。 处理应用的运行形态 除了应用与应用之间的关系外，应用运行的形态是影响“如何容器化这个应用”的重要因素。为此，Kubernetes 定义了新的、基于 Pod 改进后的对象，这些称为编排对象。比如 Job，用来描述一次性运行的 Pod（比如，大数据任务）；再比如 DaemonSet，用来描述每个宿主机上必须且只能运行一个副本的守护进程服务；又比如 CronJob，则用于描述定时任务等等。 有了编排对象之后，还需要为这些编排对象提供一些服务，于是就有了服务对象。比如 Service、Secret、Horizontal Pod Autoscaler（自动水平扩展器）等。这些对象，会负责具体的平台级功能。 这种使用方法，就是所谓的“声明式 API”。这种 API 对应的“编排对象”和“服务对象”，都是 Kubernetes 项目中的 API 对象（API Object）。]]></content>
      <categories>
        <category>技术技能</category>
        <category>全面拥抱kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Docker的安装和配置]]></title>
    <url>%2F%E6%8A%80%E6%9C%AF%E6%8A%80%E8%83%BD%2F%E5%85%A8%E9%9D%A2%E6%8B%A5%E6%8A%B1kubernetes%2FDocker%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Docker的安装一般来说，安装docker只需要下面两步即可。在执行命令之前，先切花到root用户。 12$ sudo passwd #修改密码$ su - root #切换到root用户 安装docker-ce123yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repoyum install -y docker-ce 启动docker12systemctl enable dockersystemctl restart docker 相关配置（可忽略）禁用SElinux1sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/g&apos; /etc/selinux/config 关闭防火墙1systemctl stop firewalld.service &amp;&amp; systemctl disable firewalld.service 内核优化123456789cat &gt;&gt; /etc/sysctl.conf&lt;&lt;EOFnet.ipv4.ip_forward=1net.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ip6tables=1net.ipv4.neigh.default.gc_thresh1=4096net.ipv4.neigh.default.gc_thresh2=6144net.ipv4.neigh.default.gc_thresh3=8192EOFsysctl -p 配置证书公司内网仓库需要配置证书才允许访问。 12mkdir -p /etc/docker/certs.d/e-registry.yfb.sunline.cncurl -L http://e-proxy.yfb.sunline.cn/repos/registry/e-ca.crt &gt; /etc/docker/certs.d/e-registry.yfb.sunline.cn/ca.crt docker的deamon配置配置镜像仓库的拉取地址等相关信息。 创建文件：/etc/docker/daemon.json 12345678910111213&#123; &quot;registry-mirrors&quot;: [&quot;https://c6s6uk2t.mirror.aliyuncs.com&quot;,&quot;https://e-registry.yfb.sunline.cn&quot;], &quot;insecure-registries&quot; : [&quot;e-registry.yfb.sunline.cn&quot;], &quot;max-concurrent-downloads&quot;: 3, &quot;max-concurrent-uploads&quot;: 5, &quot;storage-driver&quot;: &quot;overlay2&quot;, &quot;storage-opts&quot;: [&quot;overlay2.override_kernel_check=true&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;100m&quot;, &quot;max-file&quot;: &quot;3&quot; &#125;&#125; 最后，相关配置完成后，记得重启docker 1systemctl restart docker 查看是否安装完毕： 1docker version 运行nginx容器，查看是否安装正确1docker run -d -p 8080:80 nginx 访问容器的ip+监听端口：http://172.168.1.10:8080/代表启动成功。]]></content>
      <categories>
        <category>技术技能</category>
        <category>全面拥抱kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[深入理解容器镜像]]></title>
    <url>%2F%E6%8A%80%E6%9C%AF%E6%8A%80%E8%83%BD%2F%E5%85%A8%E9%9D%A2%E6%8B%A5%E6%8A%B1kubernetes%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[在上一篇文章容器基础之障眼法中讲到，docker容器进程，实际上就是在创建容器进程时，指定了这个进程需要启用的一组Namespace参数，然后为进程设置指定的Cgroups参数。实际上，在创建一个容器的时候，还有一个步骤，也就是本文的重点切换进程的根目录，修改容器进程对文件系统“挂载点”的认知。 在一个容器进程启动后，如果不执行挂载操作，那么容器进程看到的，就是当前宿主机的文件系统。linux提供了一个用于改变进程进程根目录的命令：chroot.例如： 1chroot $HOME/tmp /bin/bash 它的作用就是将$HOME/tmp作为 /bin/bash 的根目录。 容器镜像的定义-rootfs根文件系统这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。 由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。 对于大多数开发者而言，他们对应用依赖的理解，一直局限在编程语言层面。但实际上，一个一直以来很容易被忽视的事实是，对一个应用来说，操作系统本身才是它运行所需要的最完整的“依赖库”。 所以，一个最常见的 rootfs，或者说容器镜像，会包括如下所示的一些目录和文件，比如 /bin，/etc，/proc 等等： 12ls /bin dev etc home lib lib64 mnt opt proc root run sbin sys tmp usr var 需要明确的是，rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。 所以说，rootfs 只包括了操作系统的“躯壳”，并没有包括操作系统的“灵魂”。 那么，对于容器来说，这个操作系统的“灵魂”又在哪里呢？ 实际上，同一台机器上的所有容器，都共享宿主机操作系统的内核。 这就意味着，如果你的应用程序需要配置内核参数、加载额外的内核模块，以及跟内核进行直接的交互，你就需要注意了：这些操作和依赖的对象，都是宿主机操作系统的内核，它对于该机器上的所有容器来说是一个“全局变量”，牵一发而动全身。 不过，正是由于 rootfs 的存在，容器才有了一个被反复宣传至今的重要特性：一致性。无论在本地、云端，还是在一台任何地方的机器上，用户只需要解压打包好的容器镜像，那么这个应用运行所需要的完整的执行环境就被重现出来了。 容器镜像的分层不过，这时你可能已经发现了另一个非常棘手的问题：容器镜像的更新问题。 比如，我现在用 Ubuntu 操作系统的 ISO 做了一个 rootfs，然后又在里面安装了 Java 环境，用来部署我的 Java 应用。那么，我的另一个同事在发布他的 Java 应用时，显然希望能够直接使用我安装过 Java 环境的 rootfs，而不是重复这个流程。 Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。 123456789101112docker image inspect ubuntu:latest... &quot;RootFS&quot;: &#123; &quot;Type&quot;: &quot;layers&quot;, &quot;Layers&quot;: [ &quot;sha256:f49017d4d5ce9c0f544c...&quot;, &quot;sha256:8f2b771487e9d6354080...&quot;, &quot;sha256:ccd4d61916aaa2159429...&quot;, &quot;sha256:c01d74f99de40e097c73...&quot;, &quot;sha256:268a067217b5fe78e000...&quot; ] &#125; 事实上，镜像的分层可以分为三个部分： 第一部分：可读写层最上面这个可读写层的作用，就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用 docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub 上，供其他人使用； 第二部分：Init层需要这样一层的原因是，这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。 可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。 所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行 docker commit 只会提交可读写层，所以是不包含这些内容的。 通过“分层镜像”的设计，以 Docker 镜像为核心，来自不同公司、不同团队的技术人员被紧密地联系在了一起。而且，由于容器镜像的操作是增量式的，这样每次镜像拉取、推送的内容，比原本多个完整的操作系统的大小要小得多；而共享层的存在，可以使得所有这些容器镜像需要的总空间，也比每个镜像的总和要小。这样就使得基于容器镜像的团队协作，要比基于动则几个 GB 的虚拟机磁盘镜像的协作要敏捷得多。 第三部分：只读层不允许用户修改。用户可以继承自这些公共的分层来打包自己的镜像。 最终，这些所有的分层目录，被联合挂载在一起，形成一个完整的操作系统文件以供容器使用。 总结：在启动一个容器的时候，会执行以下几个步骤： 启用 Linux Namespace 配置； 设置指定的 Cgroups 参数； 切换进程的根目录（Change Root）。 容器镜像更多的是指rootfs，也就是容器进程运行所需要的运行环境-根文件系统。]]></content>
      <categories>
        <category>技术技能</category>
        <category>全面拥抱kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用vagrant搭建虚拟机]]></title>
    <url>%2F%E6%8A%80%E6%9C%AF%E6%8A%80%E8%83%BD%2F%E5%85%A8%E9%9D%A2%E6%8B%A5%E6%8A%B1kubernetes%2F%E4%BD%BF%E7%94%A8vagrant%E6%90%AD%E5%BB%BA%E8%99%9A%E6%8B%9F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[搭建虚拟机详细可以参考这篇博客：https://blog.csdn.net/yjk13703623757/article/details/70040797 1、安装virtualbox下载地址：https://www.virtualbox.org/wiki/Downloads mac机器上安装如果报错，需要到 系统偏好设置下-&gt;安全与隐私-&gt;通用 下，允许程序写入文件。然后再重新安装。 2、安装vagrant下载地址：https://www.vagrantup.com/downloads.html 下载安装后，在控制台上查看是否安装成功。 12$ vagrant -vVagrant 2.2.5 3、选择虚拟机的box获取虚拟机box的方式有两种，在线和离线。在线的方式，可以在https://app.vagrantup.com/boxes/search 上面找到自己想要启动的虚拟机，然后按照指示在Vagrantfile上面进行配置。 123Vagrant.configure(&quot;2&quot;) do |config| config.vm.box = &quot;bento/centos-7.4&quot;end 也可以使用离线的方式下载好虚拟机的box，然后通过 123$ vagrant box add centos.box # 添加进去。$ vagrant box list #查看已经导进去的boxbento/centos-7.4 (virtualbox, 0) 4、启动虚拟机(1)首先，创建一个目录，在目录上创建Vagrantfile 123$ vagrant init bento/centos-7.4 $ lsVagrantfile Vagrantfile的内容如下： 123Vagrant.configure(&quot;2&quot;) do |config|config.vm.box = &quot;bento/centos-7.4&quot;end (2) 启动虚拟机： 1$ vagrant up (3) 登陆虚拟机： 1$ vagrant ssh 至此，虚拟机就启动成功了。 此外，可以对虚拟机的网络，主机名称，内存等进行进一步的配置，修改Vagrantfile。 我搭建了两台虚拟机，一台是master，一台note1，主要是名称和绑定的静态ip不一样罢了。 master 虚拟机配置 12345678910111213Vagrant.configure(2) do |config| config.vm.box = &quot;bento/centos-7.4&quot; config.vm.box_check_update = false ### node1 config.vm.define &quot;master&quot; do |node| node.vm.hostname = &quot;master&quot; node.vm.network &quot;private_network&quot;, ip: &quot;172.168.1.10&quot; config.vm.provider &quot;virtualbox&quot; do |vb| # Use VBoxManage to customize the VM. vb.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, &quot;2048&quot;] end endend note1虚拟机配置： 12345678910111213Vagrant.configure(2) do |config| config.vm.box = &quot;bento/centos-7.4&quot; config.vm.box_check_update = false ### node1 config.vm.define &quot;node1&quot; do |node| node.vm.hostname = &quot;node1&quot; node.vm.network &quot;private_network&quot;, ip: &quot;172.168.1.11&quot; config.vm.provider &quot;virtualbox&quot; do |vb| # Use VBoxManage to customize the VM. vb.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, &quot;2048&quot;] end endend Vagrant命令这些命令需要进入到Vagrantfile文件所在的目录执行。]]></content>
      <categories>
        <category>技术技能</category>
        <category>全面拥抱kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[容器基础之障眼法]]></title>
    <url>%2F%E6%8A%80%E6%9C%AF%E6%8A%80%E8%83%BD%2F%E5%85%A8%E9%9D%A2%E6%8B%A5%E6%8A%B1kubernetes%2F%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[上一篇文章讲到，“容器编排”是容器世界的“顶上战争”，是最有价值的部分。不过，在了解Kubernetes的容器编排之前，我们要先打好容器的基础。 容器其实是一种沙盒技术，它把你的应用装起来，应用和应用之间是独立的，不会相互干扰。而被装进集装箱的应用也可以方便地搬来搬去。想象一种情况，当前的应用因为本地的内存不够挂了，然后容器就会在另一个合适的地方重启启动一个应用提供服务，保证服务的持续和稳定。 这种能力，究竟是怎么实现的呢?答案就是今天的主题——Linux提供的障眼法工具：Namespace和Cgroups。 从进程开始讲起我们编写的程序最终都要编译为机器认识的二进制，才能在机器上运行。在程序启动之前，它是静态的，安安静静的呆在磁盘中，但是当程序被执行起来了，它就从磁盘上的二进制文件，变成了计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件、以及各种设备的状态信息的集合。像这样一个程序运行起来后的计算机执行环境的综合，就是我们这一小节的主角：进程。 而容器的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。 容器的隔离之术：Namespace蒙蔽进程的双眼Namespace技术是Linux用来修改进程的视图的工具，简单来说，就是蒙蔽进程的双眼，让进程以为自己看到的就是所有，让进程生活在自己的世界中。 举个例子，我们用大名鼎鼎的docker run创建一个容器： 1$ docker run -it ubuntu /bin/sh -it告诉容器项目，在启动容器的时候，需要为我们分配一个文本输入输出环境，也就是TTY。这条指令的意思：请帮我启动一个容器，在容器里执行/bin/sh，并且为我分配一个命令行终端跟我这个容器交互。 进入容器后，你执行以下ps命令，会发现： 123PID USER TIME COMMAND 1 root 0:00 /bin/sh10 root 0:00 ps 也就是说，在容器里面，它以为它是老大。而事实上，这个容器在宿主机上只是一个最普通的进程。也就是说，它被“隔离”了 这种技术，就是Linux里面的Namespace机制。而Namespace它其实只是Linux创建新进程的一个可选参数。 在linux系统中创建线程/进程的系统调用是clone(),例如,我们在创建进程的时候，传入CLONE_NEWPID的参数： 1int pid = clone(main_funtion,stack_size,CLONE_NEWPID | SIGCHLD,NULL); 这时，新创建的进程将会看到一个全新的空间，在这个进程空间里，它的PID是1，而在宿主机，这个进程的PID还是真实的数值，例如100。 除了PID命名空间障眼法，Linux还提供了其他各种进程上下文的障眼法。如Mount、UTS、IPC、Network、User。比如：Mount Namespace，用于让被隔离的进程，只看到当前空间的挂载信息。Network Namespace 用户让进程只看到当前的网络设备和配置。 所以，Docker容器这个听起来玄而又玄的概念，实际上就是在创建容器进程时，指定了这个进程需要启用的一组Namespace参数。让进程只看到当前命名空间所限定的资源、文件、设备、状态、配置。而对于宿主机以及其他不相关的程序，它就完全看不到了。 容器的限制之术：Cgroups困住进程的手脚使用Namespace技术蒙蔽进程了双眼，但是对于宿主机来说，这些被隔离的进程跟其他进程没有太大的区别。这就意味着，虽然进程表面被隔离了，但是它所能够使用到的资源（比如CPU、内存）却是可以随时被宿主机上的其他进程或者容器占用的。当然，这个被隔离的进程也可以把宿主机的资源全部吃光。 于是，我们希望能够对这个进程使用的资源进行限制。 Cgroups在系统内核的作用是用来统一将进程进行分组，并在分组的基础上对进程进行监控和资源控制管理等。Cgroups的全称是Linux Control Group。它能够限制一个进程组能够使用的资源上限，包括CPU、内存、磁盘、网络带宽等等。 在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。不同的操作系统的展现形式和存储的位置可能不一样的，所以，docker 提供了统一的配置参数入口。具体可以参考官网：https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources。 例如： 1$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash 这条命令意味着，启动的这个容器进程组，在每100000us(100ms)的时间里，只能使用20000us(20ms)的CPU时间。也就是说，改进程组只能使用20%的CPU带宽。 在容器的使用过程中，如果能及时的掌握容器使用的系统资源，无论对开发还是运维工作都是非常有益的。幸运的是 docker 自己就提供了这样的命令：docker stats。 1$ docker stats 默认情况下，stats 命令会每隔 1 秒钟刷新一次输出的内容直到你按下 ctrl + c。下面是输出的主要内容：[CONTAINER]：以短格式显示容器的 ID。[CPU %]：CPU 的使用情况。[MEM USAGE / LIMIT]：当前使用的内存和最大可以使用的内存。[MEM %]：以百分比的形式显示内存使用情况。[NET I/O]：网络 I/O 数据。[BLOCK I/O]：磁盘 I/O 数据。[PIDS]：PID 号。 容器技术的优缺点docker容器和虚拟机技术相比，有一定的优势和缺点，下面我们来盘点一下。这幅图的左边，画出了虚拟机的工作原理。其中，名为 Hypervisor 的软件是虚拟机最主要的部分。它通过硬件虚拟化功能，模拟出了运行一个操作系统需要的各种硬件，比如 CPU、内存、I/O 设备等等。然后，它在这些虚拟的硬件上安装了一个新的操作系统，即 Guest OS。而APP就在这些Guest OS上面运行。 而右图，APP直接运行在宿主机的操作系统上，而docker容器更多的是旁路式的辅助和管理功能。 根据实验，一个运行着 CentOS 的 KVM 虚拟机启动后，在不做优化的情况下，虚拟机自己就需要占用 100~200 MB 内存。此外，用户应用运行在虚拟机里面，它对宿主机操作系统的调用就不可避免地要经过虚拟化软件的拦截和处理，这本身又是一层性能损耗，尤其对计算资源、网络和磁盘 I/O 的损耗非常大。 而相比之下，容器化后的用户应用，却依然还是一个宿主机上的普通进程，这就意味着这些因为虚拟化而带来的性能损耗都是不存在的；而另一方面，使用 Namespace 作为隔离手段的容器并不需要单独的 Guest OS，这就使得容器额外的资源占用几乎可以忽略不计。 所以说，“敏捷”和“高性能”是容器相较于虚拟机最大的优势，也是它能够在 PaaS 这种更细粒度的资源管理平台上大行其道的重要原因。 不过，有利就有弊，基于 Linux Namespace 的隔离机制相比于虚拟化技术也有很多不足之处，其中最主要的问题就是：隔离得不够彻底。 首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。这意味着，如果你要在 Windows 宿主机上运行 Linux 容器，或者在低版本的 Linux 宿主机上运行高版本的 Linux 容器，都是行不通的。 其次，在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。 此外，由于上述问题，尤其是共享宿主机内核的事实，容器给应用暴露出来的攻击面是相当大的，应用“越狱”的难度自然也比虚拟机低得多。 总结:容器的底层实现，是使用了Linux提供的隔离和限制的技术(Namespace和Cgroup)。APP直接运行在宿主机的操作系统上，docker容器更多的是旁路式的辅助和管理功能。这种设计使得应用的运行变得异常的高效和敏捷。当然，也会引入隔离不充分的一些问题。 当大家都以为应用是运行在容器引擎之上，容器之间有着独立的运行空间，相互之间不会干扰的时候，你可以会心一笑：这些都只不过是障眼法罢了。]]></content>
      <categories>
        <category>技术技能</category>
        <category>全面拥抱kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[小鲸鱼大事件]]></title>
    <url>%2F%E6%8A%80%E6%9C%AF%E6%8A%80%E8%83%BD%2F%E5%85%A8%E9%9D%A2%E6%8B%A5%E6%8A%B1kubernetes%2F%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%A4%A7%E4%BA%8B%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[本文大部分内容来自极客时间张磊开设的课程《深入剖析Kubernetes》。学习之前，先讲一个关于容器的故事。 2013-初出茅驴2013年的后端技术领域，已经太久没有出现过令人兴奋的东西了。虚拟机和云计算已经成为了一种基础设置。 在当时，主流用户的做法就是租一批AWS的虚拟机，然后像管理物理机一样，用脚本和手工的方式在这些机器上部署应用。 在虚拟机上部署会遇到一个痛点：云端虚拟机和本地环境不一致。所以，当时云计算服务pk的，就是谁能够更好地模拟本地服务器环境，就能够带来更好的“上云”体验。而PaaS开源项目的出现，就是解决这个问题的最佳方案。 PaaS项目被大家接纳的一个主要原因，就是它提供了一种名叫”应用托管”的能力。PaaS能够为每一个应用单独创建一个叫做“SandBox”的隔离环境，然后Sandbox中启动这些应用进程。这样，就实现了把多个用户的应用互不干涉地在虚拟机里批量、自动运行起来的目的。这就是PaaS的最核心的能力，同时也是致命软肋。 用户一旦使用了Paas打包，就必须为每种语言、框架甚至每个版本的应用维护一个打好的包，这个包主要是可执行文件+脚本+配置。更令人抓狂的是，经常出现明明在本地运行好好的程序，却需要做很多修改和配置的工作才能够在Paas中运行起来，真是为了迎合Paas，费劲用户的心机。 这个时候，一家不知名的公司dotCloud的公司，默默的开源了自己的容器项目Docker。显然，这个决定在当时根本没有人在乎。 然而，在短短的几个月，Docker项目就迅速崛起了，速度之快，以至于所有的PaaS社区还没来得及成为它的竞争对手，就直接被宣告出局了。 Docker是怎么处理这个令用户抓狂的打包操作的呢？Docker使用镜像来解决应用打包的问题。所谓镜像，就是一个压缩包。这个Docker镜像的包是直接由一个完整操作系统的所有文件和目录构成的，这个压缩包里的内容跟你本地开放测试环境用的操作系统是完全一样的。这就解决了本地环境和云环境不一致的问题，这正是Docker镜像的精髓所在。 制作镜像只需要一个命令： 1$ docker build &quot;我的镜像&quot; 此外，Docker一开始给人一种“态度可掬”的诚恳姿态，服务的对象就是普通的开发者，而不是大公司，因此得到了最广大的开发者群体的拥护。这也是Docker能够一举走红的重要原因。 2014-群雄并起Docker项目的发展趋势一日千里，但公司管理成却有着一种无法释怀的担忧。他们心里明白，虽然Docker的项目备受追捧，但用户们最终想要部署的，还是他们的网站、服务、数据库甚至是云计算业务。 这就意味着，只有那些能够能够为用户提供平台层能力的工具，能够交付用户真正价值的产品，用户才愿意付费。而这，也就是无所先驱们折戟沉沙的PaaS之路。如果无法提供平台层的能力，Docker无疑会被慢慢沦为幕后英雄。 于是，Docker公司在2014年，就确定了必须重走Paas的道路，走上了平台化的发展方向。同年，Docker的好基友CoreOS与Docker停止合作，并发布了Rocket容器。 Docker在2014年12月，发布了Swarm。Swarm最大的亮点就是，使用Docker项目容器管理的API来完成集群管理。 Docker借助这波浪潮，不断去完善自己的平台层的能力。 收购Fig项目。Fig项目是在当时的git上热度堪比docker的明星。Fig在开发者面前，第一次提出了“容器编排”的概念，简单来说就是对容器的配置和容器间的关系进行编排配置。Fig项目也就是docker-compose的前身。 收购SocketPlan项目。专门处理容器网络的项目。 收购Tutum项目。专门用来做图形化管理界面和对外提供服务的项目。一时之间，整个后端和云计算领域的聪明才俊都汇集在了这个小鲸鱼的周围，为Docker这个生态的蓬勃发展献上了自己的智慧。真所谓得道多助！ 除了这个异常繁荣精彩的Docker生态发展外，还有另一个势力在当时也是风头无两，这就是老牌集群管理项目Mesos和它背后的创业公司Mesosphere。 虽然不能提供像Swarm那样的原生Docker API，Mesos社区却拥有一个独特的竞争力：超大规模集群的管理经验。 早在几年之前，Mesos就已经通过万台节点的验证，2014年之后，又被广泛使用在eBay等大型互联网公司的生产环境中。 而CoreOS的境地却有些尴尬，它的rkt容器完全打不开局面。同样处境不容乐观的还有RedHat，它现在只剩下OpenShift和经典的PaaS的牌可以打。跟Docker Swarm和Mesos完全不在同一个竞技水平上竞争。 那么，事实真的就这样持续下去吗？ 2014年注定是一个神奇的年份。就在这一年的6月份，基础设置的翘楚Google公司突然发力，正式宣布一个名为Kubernetes项目诞生。而这个项目，不仅挽救了当时的CoreOS和RedHat，还如同当年Docker项目的横空出世一样，再一次改变了整个容器市场的格局。 2015~2016 尘埃落定Docker项目此时已经成为Docker公司的一个商业产品，而开源知识Docker公司吸引开发者群体的一个重要的手段。不过，这么多年来，开源社区的商业化其实都是类似的思路，无非是高不高调，心不心急的问题罢了。Docker公司在开源项目上的强势的话语权，渐渐令大多数的开发者不满意。于是，一场变革似乎在慢慢酝酿着。 程序员就是这么桀骜不驯的群体，在开源的世界里，得开发者的天下。 于是，Google、RedHat等开源基础设施领域的玩家们，共同牵头发起了一个CNCF(Cloud Native Computing Foundation)的基金会，也就是如今风头一时的云原生概念由来。这个基金会的目的，就是建立一个由开源基础设置领域厂商主导的、按照独立基金会方式运营的平台级社区，来对抗以Docker公司为核心的容器商业生态。 CNCF基金会成功的做好了以下两件事： Kubernetes项目能够在容器编排领域取得足够大的竞争优势。 CNCF社区以Kubernetes项目为核心，覆盖足够多的场景。 就这样，Kubernetes项目在Github上的各项指标开始一骑绝尘，将Swarm项目远远地甩在了身后。 在已经囊括了监控事实标准的Promutheus项目之后，CNCF社区迅速在成员项目中添加了Fluentd、OpenTracing、CNI等一系列容器生态的知名工具和项目。看到了CNCF表现出来的巨大吸引力，大量的公司和开发者纷纷倒向了Kubernetes生态。 而面对这样的竞争态势，Docker公司终于支撑不住，决定孤注一掷，在2016年，放弃了Swarm项目，将容器编排和集群管理功能全部内置到Docker项目中，放弃PaaS，退守后端，成为docker容器生态的幕后英雄。 而此时，Kubernetes的应对策略则是反其道而行。开始在整个社区推进“民主化”的架构，即：从API到容器运行时的每一层，Kubernetes项目都为开发者暴露出了可以扩展的插件机制，鼓励用户通过代码的方式接入到Kubernetes项目的每一个阶段。很快，Kubernetes的生态变得异常繁荣。曾经纷纷扰扰的容器技术圈子，开始回归沉静。2017、2018到现在，也没有在这个方向上发生革命性的变化，至此，容器的技术尘埃落定。 总结： 容器技术的兴起，起源于PaaS技术的普及； Docker公司发布的Docker开源项目，具有里程碑意义。Docker项目通过“容器镜像”的方式，解决了当时打包难的问题。 容器本身没有价值，更有价值的是“容器编排”，“容器编排”的纷争，以Kubernetes的胜利而告终。 得开发者、得社区者的天下。]]></content>
      <categories>
        <category>技术技能</category>
        <category>全面拥抱kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[学一点金融之宏观经济分析]]></title>
    <url>%2F%E9%A2%86%E5%9F%9F%E8%A1%8C%E4%B8%9A%2F%E9%87%91%E8%9E%8D%E6%80%9D%E7%BB%B4%2F%E5%AD%A6%E4%B8%80%E7%82%B9%E9%87%91%E8%9E%8D%E4%B9%8B%E5%AE%8F%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[如何对经济周期进行预判和分析信贷周期决定经济周期 你想一下就明白了，工业社会是依靠规模化生产来降低成本、提高产量的。 而规模化生产，就必然要求大规模资金的投入。这种情况下，光依靠个体的 自有资金，原始积累就不够。所以，必须依靠大规模的资金借贷市场。换句 话说，信贷的规模会决定社会生产的规模。 人们对未来的预期决定信贷规模 如果咱们大家都觉得现在经济状态比较好，多生产能赚更多的利润，那企业就想干什么呢?企业就一定想去借钱，扩大再生产。而银行同时也会愿意贷款给企业，因为觉得既安全回报率又高。 反之，如果风险太高，银行开始急着抽贷(将资金回笼保证资金安全)，企业会忙着收缩生产，整个经济就转入萧条，甚至衰退。 政府调节经济过冷，担心会产生失业这种情况。 经济过热也不好，因为资产价格飙升，会把贫富差距拉大。所以，为了避免 这种过度的波动，现代的国家和政府会进行一些“逆周期”的调节。 经济过热 提高资金价格(提高利率) 减少资金数量(提高准备金率) 经济过冷 降低资金价格 多放水 关键指标投资完成率 基本判断:中国是资本驱动的经济体 GDP国内生产总值（GDP）指按市场价格计算的一个国家(或地区)所有常住单位在一定时期内生产活动的最终成果，常被公认为衡量国家经济状况的最佳指标。国内生产总值GDP是核算体系中一个重要的综合性统计指标，也是我国新国民经济核算体系中的核心指标，它反映了一国（或地区）的经济实力和市场规模。 GDP并不适合衡量一个地区或城市的经济状况，因为每个城市的生产总值上缴上级或国家的量都不同，所以在每个城市留下的财富就不一样 CPI CPI是居民消费价格指数(consumer priceindex)的简称。居民消费价格指数，是一个反映居民家庭一般所购买的消费品和服务项目价格水平变动情况的宏观经济指标. PPI PPI就是Producer Price Index的简称，就是平时你在媒体上经常听说的生产者价格指数。这个指 数和消费者价格指数CPI，反映了一个国家或者说一个市场的价格水平。 而PPI关注的主要是生产端，CPI关注的主要是消费端。上涨代表经济景气，4%—7%是普遍认为好的指数，过高过低都不太好 美林时钟理论GDP高，CPI低，经济繁荣;GDP高，CPI高，经济过热;GDP低，CPI高，经济滞胀;GDP低，CPI低，经济衰退。 如何判断当前经济的现状冷暖GDP的比较 6.9(2017) 6.6(2018) 说明经济正在走下行道路。 直观感受失业股市消费 后期的规划“硬约束”，那就是党在十八大文件中明确强调过的“到2020年年底，中国经 济要翻番”的目标。 根据前些年中国经济增长的情况，如果我们要完成2020年经济翻番的目标 的话，2019年和2020年大约要维持6.2%到6.3%的GDP增速，稍微增加一 点点安全边际，那应该把这两年的增速维持在6.4%、6.5%左右。 问题?如何理解经济翻番，跟哪一年比较?和GDP什么关系? 政府出台的货币和财政政策 梳理2018年12月以来，可以告诉你的是，在一个半月不到的时间里，大概有 将近20项比较大的政策出台，都指向更宽松的货币和财政政策。 结论:政府要实施促进的宽松政策 如何根据经济周期做出投资决策 整体上，如果经济十分不景气，那就现金为王。在经济周期拐点刚刚出现的时 候，很多行家会配置债券，然后随着经济的转暖，配置股票。 投资原则第一条原则:生命周期原则一个人的资产配置必须和你一生的现金流还有时间是相适应的。 在年轻的时候，要尽量配置一些长期的大额实物资产，使用贷款加点杠杆，用时间换空间。 在中年，现金流充裕的情况下，首先要为上老下小配置养老、医疗和教育的保险。然后，在这个基础上，加大风险资产的投资，比如股票、股权投资等等，去追求高收益。 老年，低杠杆，低风险，高流动性是资产配置的第一原则 第二条原则:风险匹配原则简单粗暴。根据经济周期的冷热，只要是年化利率超过15%到20%的投资 ，你都需要非常谨慎。 拜托啊，兄弟，这样高回报的投资项目，在市场上早被抢疯了，怎么还会需要推销呢?不懂不投，就是我们的第二原则的精髓。 投资决策###回顾过去 通货膨胀率从2007年到现在，通货膨胀率平均是2.5%，也就是说如果你家的积蓄 ，每年的收益率在2.5%以下，那就是资产贬值了。 过去十年存银行定期是赔钱货，因为一年期的存款利率比通货膨胀率低了 差不多60%。 另外投A股的大盘也是赔钱货，过去十年，大盘的平均收益是1.5%，也是 比通货膨胀率低的。 那过去十年真正替你赚钱的是什么呢?一线和核心二线城市的房产，平均 年化利率都在10%左右，还有三线城市的房产和银行的理财产品，过去十 年中也跑赢了通胀。 未来趋势第一，利率下行是基本的趋势，所以，银行的存款利率只会下，不会上，存银行仍然是赔钱货。第二，股和债都是周期性波动非常厉害的资产，在可见的未来，A股市场 有机会，可是波动性还是会很大。第三，城市房价的分化还会继续进行下去，在我们国家经济维持中到中高速增长的情况下，一线和核心二线城市的房产就像是增长的蓝筹股，安全系数高，收益也会不错。第四条就是要考虑配置一些保险，降低未来生活的不确定性。]]></content>
      <categories>
        <category>领域行业</category>
        <category>金融思维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[高手是如何解决问题的-解决复杂问题只需四步]]></title>
    <url>%2F%E7%B3%BB%E7%BB%9F%E6%80%9D%E7%BB%B4%2F%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%A1%86%E6%9E%B6%2F%E9%AB%98%E6%89%8B%E6%98%AF%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%2F</url>
    <content type="text"><![CDATA[概述面对各种各样的复杂问题，其实你拆解它、解决它的思路和手段都是相通的。面对复杂且多变的世界，找到那些不变的东西，总是那么令人心安。 其实，解决问题，只有四个步骤： 第一步，明确和理解问题； 第二步，拆分和定位问题； 第三步，提出解决方案； 第四步，总结问题。 在这四步里，提出解决方案其实放得很靠后。第二步，也就是拆解和定位问题，反而是整套方法里最重要的。 如果你想要解决问题，你就必须用80%的精力去拆解和定位这个问题，剩下20%的精力去寻找解决方案，其实就足够了。 因为，当问题被拆分得足够细、足够清晰的时候，你就会发现解决方案原来是这么明显，每个人都可以办得到。 明确及理解问题遇到具体问题时，你一定要问自己“我遇到的问题本质到底是什么？ 第一步，你要找出对方关心的问题点。 第二步是明确解决问题的目标。 第三步就是要明确可以用来解决这个问题的资源。 定位和拆解问题什么是复杂问题呢？就是掺杂了多个维度和变量的问题。那什么是元问题？就是那些最本质、最细小的待解决的问题。 复杂问题是不可直接解决的。你每天都在应对各种各样复杂问题的时候，其实都是在下意识地把这个复杂问题做拆解，然后再去一一地解决掉。 用公式思维拆解问题例如:广告收入=展现量×点击率×每个点击的价格 。煎饼摊的月利润 = 每天卖出的煎饼数量 × 每套煎饼的价格 × 每月工作天数 - 煎饼运营一个月的总成本；同样，你可以找到计算深圳地铁一天的运客量，深圳的理发店数量的办法。地铁每日的运客量 = 地铁数量 × 每条地铁装载的人数 拆解问题的推理模式一个叫假设驱动，一个叫构建问题树 “假设驱动”的理念其实是从科研界沿用出来的，它的意思是，在应对复杂问题、寻找解决方案之前，我们先来做一个尽可能合理的假设。假设问题可能出现在某个细分的问题点上。在假设驱动之后，拆解问题的第二个重点叫做搭建问题树结构。问题树又叫逻辑树、演绎树。它其实就是一个树状结构的东西，它的一个日常的应用其实我们每个人可能都看到过，就是思维导图。这么做有两个好处： 一个是你会更容易找到问题所在；另一个是你可以根据拆解，把树上的问题都变成任务，清晰、没有遗漏地分配给其他人。 那么，面对一个复杂问题，该怎么搭建它的问题树结构呢？一共可以总结成五个小步骤： 第一，你要找出问题中存在的核心问题和起始问题。这点特别重要，之后的每一步都是基于这一点；第二，要确定导致核心问题和起始问题的主要原因；第三，要确定核心问题和起始问题导致的主要后果。第二点讲的是原因，现在是后果；第四，根据以上的因果关系画出这个问题树；第五，反复审查问题树。看看哪里还缺东西，进行最后的补充和修改。 如何把问题拆解到底其实，问题只需要拆解到我们能够处理的粒度就可以了。下面提供一个拆解问题的法则，是衡量拆分得是否合理的法则。 MECE法则：相互独立，完全穷尽！ 提出解决方案解决方案：如果上面已经拆分好了的话，解决方案就已经不言而喻了，这里也就没有描述的必要。 总结问题能够将复杂问题总结为一个结论，也是非常重要的。在做各种汇报的时候，如果没有个次重点，别人就不知道你在说什么。有时候，在跟别人讲解的时候，为了防止自己天马行空的思维，就会给自己列大纲。 下面是使用金字塔思维来陈述结论。我们要从结论不断地分拆，直到那个不可辩驳的事实；在跟别人表述的时候，我们需要自上而下地去表达。结论现行，再讲理由和事实。 总结：解决问题是有套路的，我们可以使用固定的步骤去解决多变的问题。这些步骤分别是： 第一步，明确和理解问题； 第二步，拆分和定位问题； 第三步，提出解决方案； 第四步，总结问题。]]></content>
      <categories>
        <category>系统思维</category>
        <category>解决问题的框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[没有结构化思维，PPT都写不好]]></title>
    <url>%2F%E7%B3%BB%E7%BB%9F%E6%80%9D%E7%BB%B4%2F%E7%BB%93%E6%9E%84%E5%8C%96%E6%80%9D%E7%BB%B4%2F%E6%B2%A1%E6%9C%89%E7%BB%93%E6%9E%84%E5%8C%96%E6%80%9D%E7%BB%B4%EF%BC%8CPPT%E9%83%BD%E5%86%99%E4%B8%8D%E5%A5%BD%2F</url>
    <content type="text"><![CDATA[没有结构化思维写不好PPT一天，研发中心老大张总在研发管理群里面说，今年年中要开一次年中总结，时间就定在周六。今天是周三，明天下班前把PPT写好交给我过一下。下面是PPT模板。 我如临大敌，赶紧把模板下载下来，打开一看，什么，只是公司的PPT模板，连个像样的大纲都没有？没有写过年中总结的PPT，明天就要交出版，连个头绪都没有，看来今晚又是一个不夜天！ 于是我找了公司的大牛廖哥问一下，这个年中总结有去年的模板吗?我参考一下大纲也好呀。 大牛廖哥回复，没有模板的，按照自己的想法就好了，你的主题是《开放银行的探索与实践》，主要告诉大家，开放平台的市场、研发现状、近期规划、未来设想。听了大佬的一段话，我瞬间感觉思路清晰了，也知道怎么写了。经过一天一夜的奋战，终于把PPT赶出来了。 上面PPT的结构是 从大到小:从开放银行到开放平台。 从过去到现在到未来：过去的总结，近期的工作规划以及未来的展望。 你有没有发现，面对同样的事情、问题，不同的人思考的方式是不一样的。有的人能够迅速理清复杂关系中的结构，并且有条理的表达出来，而有的人花半天都不知道如何下手。 后来感受到，这里面隐藏着一种思维能力：结构化思维。 什么是结构化思维下面用一张图解释： 纵向 结论现行，以上统下 论：也就是结论先行。 证：也就是以上统下。直到最后一个层级的内容是客观事实或数据为止。 横向 归类分组，逻辑递进 类：也就是归类分组，遵循MECE法则，不重不漏。 比：也就是逻辑递进。 纵向是总分结构，从总体到局部，从高层次的抽象到低层次的抽象。表达观点的时候，也可以采用总分结构，将表达的观点分为结论、理由、事实三层。 横向是同一个层级的事物的拆解分类。同一层级的拆解分类能够帮助我们快速理解事物的本质和关系。 拆解的原则的MECE法则，即相互独立，完全穷尽。常见的拆解方法有： 二分法：如男人、女人。 过程法：比较常用。如时间的顺序，调用的顺序等。 结构要素法：例如，我们做的开放平台的结构要素就有网关服务、管控后台、门户网站、监控服务器、各个能力中心。 特定场景：如指定目标的SMART原则(S=Specific、M=Measurable、A=Attainable、R=Relevant、T=Time-bound) 公式法：比如，盈利=总收入-成本。然后收入和成本需要根据不同场景进一步进行拆分。 如何去锻炼结构化思维思维模式是大脑长期面对事物的应对方式，想要改变不容易。 如果我们能够善于发现别人的思维模式，那么我们也会有意识地去改变自己的思维习惯了。 我们可以从日常的生活物品分类，文档的分类开始练习。此外，有一个练习的方法据说非常有效：重要的事情说三点。重要的事情说三点，能够逼迫锻炼自己的结构化思维。 总结：如果本文你只记住一句话，那就是：要使用结构化思维去思考问题。结构化思维要记住四个字：论证类比。]]></content>
      <categories>
        <category>系统思维</category>
        <category>结构化思维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[以终为始]]></title>
    <url>%2F%E7%B3%BB%E7%BB%9F%E6%80%9D%E7%BB%B4%2F10x%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95%2F%E4%BB%A5%E7%BB%88%E4%B8%BA%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[以终为始，就是在做事之前，先想想结果是什么样子的。以下为极客时间郑烨的10x工作法分享的以终为始的几个准则，希望能在工作上用上一部分。 集体想象-让我们大家想到一块去赫拉利的《人类简史》中，有一个说法：想象共同体，人类发展的一个重要因素就是”集体想象“。无论是国家、宗教还是法律习俗。 其实，我们做软件的人就是一个想象共同体，这个”集体想象“就是我们要做的软件，任何想象都需要一个载体将其展现出来，而我们编写软件的过程，就是将这个”集体想象“落地的过程。 任何事物都要经过两次创造：第一次在头脑中创造，第二次是付诸实践。相比第一次创造，第二次创造的成本非常大。 所以，我们要尽可能在头脑创造的时候，想清楚我们要做的是什么。像DDD、事件风暴都有助于我们在第一次创造做得更好。 DoD-当我们拿到需求或任务的时候，先定义需求验收的标准以终为始的思维中，首先要解决的问题就是，”终“到底是什么？一个简单的登录功能，如果不讨论清楚怎样才算是完成，那么就很有可能做出来的东西，别人并不满意。 通常来说，不同立场的人对”终“的理解是不一样的。 开发人员以为，功能只要开发完成，就算完成了。测试人员认为，功能至少要经过测试，不要出现很低级的错误才是。项目经理可能还要加上单元测试才行。产品经理会认为，整个需求测试完成可交付才算完成。。。。。用户拿到手一看，我要的手机号码登录，你给我一个用户名密码登录！！ DoD(Definition of Done):完成的定义。 如何才能更好地发挥DoD的作用： DoD清单，清单是由一个个检查项组成的，用来检查我们的工作完成情况。 DoD检查项，应该是实际可检查的，只有做完和没做完两种情况。 精益创业-面对不确定性创造新事物当需求是不确定的，那我们唯一能够做的就是尝试。那么是否能够使用最小的代价去实现这个需求？即MVP(Minimum Viable Product) 下面是精益创业的想法验证框架。 精益创业提出的 开发-测量-认知这样一个反馈循环。 也就是说，当你有一个”想法“时，就把想法开发成”产品“投入市场，然后收集”数据“获得反馈，看看前面的想法是不是靠谱。精益在于，小步伐快速验证。 持续集成-尽早去集成写代码是程序员的职责，但我们更有义务交付一个可运行的软件。 不要等到所有代码都开发完成再去做持续集成，因为改动量越大，集成过程中出现的问题就会越多，集成的时间也就越长。它们之间会形成恶性循环关系。 业界最佳实践就是，尽早把代码和已有代码集成到一起进行测试。 扩大自己的工作上下文，别局限在一个“程序员”的角色不同角色工作上的真正差异是上下文的不同。程序员喜欢以技术实现去思考问题，手里有了锤子，眼里都是钉子。程序员有自己的盲区，而看不见的原因就在于上下文的缺失。当你对软件开发的全生命周期有了认识之后，你看到的就不再是一个点了，而是一条线。 单一维度的思考，在多维度思考者眼里几乎是漏洞百出。 在动手做之前，先推演一番前面讲的内容一致都是看到结果的重要性，但通向结果的路径也同样重要。 对比我们的工作，多数情况下，即便目标是清晰的，路径却多数是模糊的。在动手之前， 将实现路径推荐一番，形成相关的文档一起讨论非常必要。 用数字来衡量我们的工作可以提炼一些关键的数字来衡量我们的工作，避免个人主观上的判断，避免人们之前“空对空”的对话。 当我们设置了测量工作的有效指标，就可以更有目的地协作和工作。 例如：单元测试覆盖率漏洞严重程度工时填写率。。 迭代0-启动开发之前，你应该准备什么 总结：敏捷迭代的思维+以终为始的思维，就是要告诉我们，在开始之前，先想好最终要做成什么样子。在做的时候，尽早去反馈，不要等到全部完成。]]></content>
      <categories>
        <category>系统思维</category>
        <category>10x程序员工作法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SourceCRT使用sftp上传下载文件]]></title>
    <url>%2F%E6%8A%80%E6%9C%AF%E6%8A%80%E8%83%BD%2FLinux%E8%BF%90%E7%BB%B4%2FSourceCRT%E4%BD%BF%E7%94%A8sftp%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[在行方环境中，经常发现没有我肯熟悉的xshell,xsft相关的界面操作工具。甚至连rz，sz也是没有的。 不过一般情况下，都会有sftp这个工具。 1 打开sftp传输窗口File → Connect SFTP Seccion 2 常用命令文件上传下载相关的命令： get: 将远程目录中文件下载到本地目录 . eg : sftp&gt; get a.txt b.txt put: 将本地目录中文件上传到远程主机(linux) eg： sftp&gt; put a.txt b.txt 支持Linux的几个目录相关命令： 服务器端：cd、pwd、ls 本地端：lcd、lpwd、lls。(l代表local) 退出命令：quit]]></content>
      <categories>
        <category>技术技能</category>
        <category>Linux运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一个框架，四个原则]]></title>
    <url>%2F%E7%B3%BB%E7%BB%9F%E6%80%9D%E7%BB%B4%2F10x%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95%2F10x%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一个思考框架 Where are we? → 现状 Where are we going? → 目标 How can we get there? → 实现路径 以上三个问题，能够帮你理清楚你即将要做的事情。同样，如果有人能够清晰地回答以上三个问题，也就说明他对要做的事情有着清晰的认识。 四个思考原则 以终为始 ，确定好真实目标。 任务分解，找到实施路径。 沟通反馈，解决与人打交道出现的问题。 自动化，解决与机器打交道出现的问题。 总结：一个框架，四个原则是对10倍程序员工作法的高度抽象。后面的文章会对这些内容进行补充。]]></content>
      <categories>
        <category>系统思维</category>
        <category>10x程序员工作法</category>
      </categories>
  </entry>
</search>
